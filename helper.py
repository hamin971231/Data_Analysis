import numpy as np
import pandas as pd
from math import sqrt
from scipy.stats import t, pearsonr, spearmanr
from sklearn.impute import SimpleImputer
from scipy.stats import shapiro, normaltest, ks_2samp, bartlett, fligner, levene, chi2_contingency
from scipy import stats
from statsmodels.formula.api import ols
#import re
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
from sklearn.model_selection import train_test_split
from pca import pca
from statsmodels.formula.api import logit
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, f1_score,recall_score,r2_score,mean_squared_error,mean_absolute_error
from sklearn.linear_model import LinearRegression

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from pmdarima.arima import auto_arima
import seaborn as sb
from matplotlib import pyplot as plt
from tabulate import tabulate

def setCategory(df, fields=[],labelling=True):
    """
    ë°ì´í„° í”„ë ˆì„ì—ì„œ ì§€ì •ëœ í•„ë“œë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - fields: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½í•  í•„ë“œëª… ë¦¬ìŠ¤íŠ¸. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸(ì „ì²´ í•„ë“œ ëŒ€ìƒ)

    Returns
    -------
    - cdf: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½ëœ ë°ì´í„° í”„ë ˆì„
    """
    cdf = df.copy()
    # ë°ì´í„° í”„ë ˆì„ì˜ ë³€ìˆ˜ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    ilist = list(cdf.dtypes.index)
    # ë°ì´í„° í”„ë ˆì„ì˜ ë³€ìˆ˜í˜•ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    vlist = list(cdf.dtypes.values)

    # ë³€ìˆ˜í˜•ì— ëŒ€í•œ ë°˜ë³µ ì²˜ë¦¬
    for i, v in enumerate(vlist):
        # ë³€ìˆ˜í˜•ì´ objectì´ë©´?
        if v == 'object':
            # ë³€ìˆ˜ëª…ì„ ê°€ì ¸ì˜¨ë‹¤.
            field_name = ilist[i]

            # ëŒ€ìƒ í•„ë“œ ëª©ë¡ì´ ì„¤ì •ë˜ì§€ ì•Šê±°ë‚˜(ì „ì²´í•„ë“œ ëŒ€ìƒ), í˜„ì¬ í•„ë“œê°€ ëŒ€ìƒ í•„ë“œëª©ë¡ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´?
            if not fields or field_name not in fields:
                continue

            # ê°€ì ¸ì˜¨ ë³€ìˆ˜ëª…ì— ëŒ€í•´ ê°’ì˜ ì¢…ë¥˜ë³„ë¡œ ë¹ˆë„ë¥¼ ì¹´ìš´íŠ¸ í•œ í›„ ì¸ë±ìŠ¤ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬
            # vc = cdf[field_name].value_counts().sort_index()
            # print(vc)

            # ì¸ë±ìŠ¤ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê°’ì˜ ì¢…ë¥˜ë³„ë¡œ ë°˜ë³µ ì²˜ë¦¬
            # for ii, vv in enumerate(list(vc.index)):
                # ì¼ë ¨ë²ˆí˜¸ê°’ ìƒì„±
                # vnum = ii + 1
                # print(vv, " -->", vnum)

                # ì¼ë ¨ë²ˆí˜¸ê°’ìœ¼ë¡œ ì¹˜í™˜
            # cdf.loc[cdf[field_name] == vv, field_name] = vnum

            # í•´ë‹¹ ë³€ìˆ˜ì˜ ë°ì´í„° íƒ€ì…ì„ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜
            cdf[field_name] = cdf[field_name].astype('category')
            if labelling : 
                mydict = {}
                for i,v in enumerate(cdf[field_name].dtypes.categories) :
                    mydict[v]=i
                cdf[field_name] = cdf[field_name].map(mydict).astype(int)

    return cdf
def replaceMissingValue(df):
    imr=SimpleImputer(missing_values=np.nan, strategy="mean")
    df_imr = imr.fit_transform(df.values)
    re_df = pd.DataFrame(df_imr,index=df.index,columns=df.columns)
    return re_df

## ì´ìƒì¹˜ë¥¼ ê²°ì¸¡ì¹˜ë¡œ ë°”ê¾¸ê¸°ì „ì— ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì•¼í•¨
def getIq(field) :
    q1 = field.quantile(0.25)
    q3 = field.quantile(0.75)
    iqr = q3 - q1
    low = q1 - 1.5 * iqr
    high = q3 + 1.5 * iqr
    bound = [low,high]
    return bound

## ì´ìƒì¹˜ë¥¼ ê²°ì¸¡ì¹˜ë¡œ ë°”ê¾¸ëŠ” í•¨ìˆ˜

def replaceOutlier(df,fieldName):
    cdf=df.copy()
    ## fieldNameì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë²¼ë…¸í•œ
    if not isinstance(fieldName,list) :
        fieldName = [fieldName]

    for f in fieldName :
        bound = getIq(cdf[f])
        cdf.loc[cdf[f]< bound[0],f] = np.nan
        cdf.loc[cdf[f]>bound[1],f] = np.nan
    return cdf

def clearStopwords(nouns,stopwords_file_path = "wordcloud/stopwords-ko.txt") :
    with open(stopwords_file_path,"r",encoding="utf-8") as f :
        stopwords = f.readlines()
        
        for i,v in enumerate(stopwords) :
            stopwords[i] = v.strip()
        data_set = []

        for v in nouns :
            if v not in stopwords :
                data_set.append(v)

        return data_set
## ì •ê·œì„± ê²€ì •
def normality_test(*any):
    ## ì¸ë±ìŠ¤ë¥¼ ìœ„í•œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    names = []

    ## ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ 
    result = {
        "Statistic" :[],
        "p-value":[],
        'Result' :[]
    }

    ## shapiro-wills Test
    for i in any :
        s, p = shapiro(i)
        result['Statistic'].append(s)
        result['p-value'].append(p)
        result['Result'].append(p>0.05)
        names.append(('ì •ê·œì„±','Shapiro',i.name))
    
    # normal Test 
    for i in any :
        s,p=normaltest(i)
        result['Statistic'].append(s)
        result['p-value'].append(p)
        result['Result'].append(p>0.05)
        names.append(('ì •ê·œì„±','normal',i.name))
    
    ## k-s ê²€ì •ì€ ì •ê·œì„± ì—¬ë¶€ë¥¼ ê°ê°ì˜ í•„ë“œ ì„œë¡œì„œë¡œ í•´ì•¼í•¨ -> ë°˜ë³µ í•„ìš”
    n = len(any)
    for i in range(0,n):
        j = i + 1 if (i < n-1) else 0
        s,p = ks_2samp(any[i],any[j])
        result['Statistic'].append(s)
        result['p-value'].append(p)
        result['Result'].append(p>0.05)
        names.append(('ì •ê·œì„±','k-s_2samp',f'{any[i].name} vs {any[j].name}'))
    
    
    return pd.DataFrame(result,index=pd.MultiIndex.from_tuples(names,names=['Condition','Test','Field']))
        
## ë“±ë¶„ì‚°ì„± ê²€ì •
def equal_variance_test(*any) :
    # statistic=1.333315753388535, pvalue=0.2633161881599037
    ## ê²€ì •ê²°ê³¼ ì €ì¥
    s1,p1 = bartlett(*any)
    s2,p2 = fligner(*any)
    s3,p3 = levene(*any)
    ## ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    names= []

    for i in any : 
        names.append(i.name)

    fix =" vs "
    name = fix.join(names) 
    index = [['ë“±ë¶„ì‚°ì„±','Bartlett',name],['ë“±ë¶„ì‚°ì„±','Fligner',name],['ë“±ë¶„ì‚°ì„±','Levene',name]]

    result = pd.DataFrame({
        'Statistic' : [s1, s2, s3],
        "p-value" : [p1, p2, p3],
        "Result" : [p1>0.05,p2>0.05,p3>0.05]
    },index=pd.MultiIndex.from_tuples(index,names=['Condition','Test','Field']))
    return result

## ë…ë¦½ì„± ê²€ì • 

def independence_test(*any):
    df = pd.DataFrame(any).T
    result = chi2_contingency(df)

    names = []
    for i in any :
        names.append(i.name)
    fix = " vs "
    name = fix.join(names)
    index = [['ë…ë¦½ì„±','Chi2',name]]
    df = pd.DataFrame({
        "Statistic":[result.statistic],
        "p-value":[result.pvalue],
        "Result":[result.pvalue>0.05]
    },index = pd.MultiIndex.from_tuples(index, names=['Condition','Test','Field']))
    return df

def all_test(*any) :
    return pd.concat([normality_test(*any),equal_variance_test(*any),independence_test(*any)])



def pearson_r(df) :
    names = df.columns 
    n = len(names)
    pv=0.05
    data = []
    for i in range(0,n):
        j=i+1 if i<(n-1) else 0
        fields = names[i] +"vs" +names[j]
        s,p = stats.pearsonr(df[names[i]],df[names[j]])
        result = p<pv
        data.append({'fields': fields, 'statistic': s, 'pvalue': p, 'result': result})
    rdf = pd.DataFrame(data)
    rdf.set_index('fields', inplace=True)
    return rdf

def ext_ols(data,y=None,x=None,expr=None) :
    """
    íšŒê·€ë¶„ì„ì„ ìˆ˜í•´í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """
    df = data.copy()
    if not expr :
        # ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if type(x) != list :
            x= [x]
        ## ì¢…ì†ë³€ìˆ˜ ~ ë…í™ë³€ìˆ˜1 + ë…ë¦½ë³€ìˆ˜2 + ... í˜•íƒœì˜ ì‹ì„ ìƒì„±
        expr = "%s ~ %s" % (y,"+".join(x))
    else : 
        x= []
        p = expr.find('~')
        y = expr[:p].strip()
        x_tmp= expr[p+1:]
        x_list = x_tmp.split('+')
        for i in x_list:
            k = i.strip()
            if k :
                x.append(k)
    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = ols(expr,data=data)
    ## që¶„ì„ìˆ˜í–‰
    fit = model.fit()
    ## ë¶„ì„ê²°ê³¼ë¥¼ ì €ì¥
    summary = fit.summary()

    ## ê²°ê³¼ì˜ ì²«ë²ˆì¨°, ì„¸ë²ˆì§¸ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´
    my = {}
    for k in range(0,3,2):
        items = summary.tables[k].data
        for item in items :
            n = len(item)
            for i in range(0,n,2) :
                key = item[i].strip()[:-1]
                value = item[i+1].strip()
                if key and value :
                    my[key]=value
    ## ë‘ë²ˆì¨° í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ 
    my['variables']=[]
    name_list = list(data.columns)
    for i , v in enumerate(summary.tables[1].data) :
        if i==0 :
            continue
        # ë³€ìˆ˜ì˜ ì´ë¦„
        name = v[0].strip()
        
        vif = 0

        # 0ë²ˆì¨°ì¸ interceptsëŠ” ì œì™¸
        if name in name_list :
            j=name_list.index(name)
            vif = variance_inflation_factor(data,j)
        my['variables'].append({
            "name": name,
            "coef": v[1].strip(),
            "std err": v[2].strip(),
            "t": v[3].strip(),
            "P-value": v[4].strip(),
            "Beta": 0,
            "VIF": vif,
        })
        ## ê²°ê³¼í‘œë¥¼ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ êµ¬ì„±
    mylist = []
    yname_list = []
    xname_list = []

    for i in my['variables'] :
        yname_list.append(y)
        xname_list.append(i['name'])

        item = {
            "B": i['coef'],
            "í‘œì¤€ì˜¤ì°¨": i['std err'],
            "Î²": i['Beta'],
            "t": "%s*" % i['t'],
            "ìœ ì˜í™•ë¥ ": i['P-value'],
            "VIF": i["VIF"]
        }

        mylist.append(item)
    table = pd.DataFrame(mylist,
                   index=pd.MultiIndex.from_arrays([yname_list, xname_list], names=['ì¢…ì†ë³€ìˆ˜', 'ë…ë¦½ë³€ìˆ˜']))
    # ë¶„ì„ê²°ê³¼
    result = "ğ‘…(%s), ğ‘…^2(%s), ğ¹(%s), ìœ ì˜í™•ë¥ (%s), Durbin-Watson(%s)" % (my['R-squared'], my['Adj. R-squared'], my['F-statistic'], my['Prob (F-statistic)'], my['Durbin-Watson'])

    # ëª¨í˜• ì í•©ë„ ë³´ê³ 
    goodness = "%sì— ëŒ€í•˜ì—¬ %së¡œ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ë¶„ì„ì„ ì‹¤ì‹œí•œ ê²°ê³¼, ì´ íšŒê·€ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ %s(F(%s,%s) = %s, p < 0.05)." % (y, ",".join(x), "ìœ ì˜í•˜ë‹¤" if float(my['Prob (F-statistic)']) < 0.05 else "ìœ ì˜í•˜ì§€ ì•Šë‹¤", my['Df Model'], my['Df Residuals'], my['F-statistic'])

    # ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
    varstr = []

    for i, v in enumerate(my['variables']):
        if i == 0:
            continue
        
        s = "%sì˜ íšŒê·€ê³„ìˆ˜ëŠ” %s(p%s0.05)ë¡œ, %sì— ëŒ€í•˜ì—¬ %s."
        k = s % (v['name'], v['coef'], "<" if float(v['P-value']) < 0.05 else '>', y, 'ìœ ì˜ë¯¸í•œ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤' if float(v['P-value']) < 0.05 else 'ìœ ì˜í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤')

        varstr.append(k)

    # ë¦¬í„´
    return (model, fit, summary, table, result, goodness, varstr)

class RegMetric:
    def __init__(self, y, y_pred):
        # ì„¤ëª…ë ¥
        self._r2 = r2_score(y, y_pred)
        # í‰ê· ì ˆëŒ€ì˜¤ì°¨
        self._mae = mean_absolute_error(y, y_pred)
        # í‰ê·  ì œê³± ì˜¤ì°¨
        self._mse = mean_squared_error(y, y_pred)
        # í‰ê·  ì˜¤ì°¨
        self._rmse = np.sqrt(self._mse)
        
        # í‰ê·  ì ˆëŒ€ ë°±ë¶„ì˜¤ì°¨ ë¹„ìœ¨
        if type(y) ==pd.Series:
            self._mape = np.mean(np.abs((y.values - y_pred) / y.values) * 100)
        else:
            self._mape = np.mean(np.abs((y - y_pred) / y) * 100)
        
        # í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨
        if type(y) == pd.Series:   
            self._mpe = np.mean((y.values - y_pred) / y.values * 100)
        else:
            self._mpe = np.mean((y - y_pred) / y * 100)

    @property
    def r2(self):
        return self._r2

    @r2.setter
    def r2(self, value):
        self._r2 = value

    @property
    def mae(self):
        return self._mae

    @mae.setter
    def mae(self, value):
        self._mae = value

    @property
    def mse(self):
        return self._mse

    @mse.setter
    def mse(self, value):
        self._mse = value

    @property
    def rmse(self):
        return self._rmse

    @rmse.setter
    def rmse(self, value):
        self._rmse = value

    @property
    def mape(self):
        return self._mape

    @mape.setter
    def mape(self, value):
        self._mape = value

    @property
    def mpe(self):
        return self._mpe

    @mpe.setter
    def mpe(self, value):
        self._mpe = value

class OlsResult :
    def __init__(self):
        self._x_train = None
        self._y_train = None
        self._train_pred = None
        self._x_test = None
        self._y_test = None
        self._test_pred = None




        self._model = None
        self._fit = None
        self._summary = None
        self._table = None
        self._result = None
        self._goodness = None
        self._varstr = None
        self._coef =None
        self._intercept = None
        self._trainRegMetric = None
        self._testRegMetric = None
        
    @property
    def x_train(self):
        return self._x_train

    @x_train.setter
    def x_train(self, value):
        self._x_train = value

    @property
    def y_train(self):
        return self._y_train

    @y_train.setter
    def y_train(self, value):
        self._y_train = value

    @property
    def train_pred(self):
        return self._train_pred

    @train_pred.setter
    def train_pred(self, value):
        self._train_pred = value

    @property
    def x_test(self):
        return self._x_test

    @x_test.setter
    def x_test(self, value):
        self._x_test = value

    @property
    def y_test(self):
        return self._y_test

    @y_test.setter
    def y_test(self, value):
        self._y_test = value

    @property
    def test_pred(self):
        return self._test_pred

    @test_pred.setter
    def test_pred(self, value):
        self._test_pred = value

    @property 
    def model(self) :
        """
        ë¶„ì„ëª¨ë¸
        """
        return self._model
    @model.setter
    def model(self,value):
        self._model = value 
    @property
    def fit(self) :
        """
        ë¶„ì„ê²°ê³¼ ê°ì²´
        """
        return self._fit
    @fit.setter
    def fit(self,value):
        self._fit = value
    
    @property
    def summary(self):
        """
        ë¶„ì„ê²°ê³¼ ìš”ì•½ ë³´ê³ 
        """
        return self._summary
    @summary.setter
    def summary(self,value):
        self._summary = value
    @property 
    def table(self):
        """
        ê²°ê³¼í‘œ
        """
        return self._table
    @table.setter
    def table(self,value):
        self._table = value
    @property
    def result(self):
        """
        ê²°ê³¼í‘œ ë¶€ê°€ ì„¤ëª…
        """
        return self._result
    @table.setter
    def result(self,value) :
        self._result=value
    @property
    def goodness(self):
        """
        ëª¨í˜• ì í•©ë„ ë³´ê³ 
        """
        return self._goodness
    @goodness.setter
    def goodness(self,value):
        self._goodness=value
    @property
    def varstr(self):
        """
        ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
        """
        return self._varstr

    @varstr.setter
    def varstr(self, value):
        self._varstr = value

    @property
    def coef(self):
        return self._coef
    @coef.setter
    def coef(self,value):
        self._coef = value
    
    @property
    def intercept(self):
        return self._intercept
    @intercept.setter
    def intercept(self,value):
        self._intercept= value
    @property
    def trainRegMetric(self):
        return self._trainRegMetric
    @trainRegMetric.setter
    def trainRegMetric(self,value):
        self._trainRegMetric = value
    @property
    def testRegMetric(self):
        return self._testRegMetric
    @testRegMetric.setter
    def testRegMetric(self,value):
        self._testRegMetric = value
    def setRegMetric(self,y_train,y_train_pred,y_test=None,y_test_pred=None):
        self.trainRegMetric = RegMetric(y_train,y_train_pred)

        if y_test is not None and y_test_pred is not None :
            self.testRegMetric = RegMetric(y_test,y_test_pred)           
	
def my_ols(data,x,y,expr=None) :
    model, fit, summary, table, result, goodness, varstr = ext_ols(data, y, x)
    ols_result = OlsResult()
    ols_result.model = model
    ols_result.fit = fit
    ols_result.summary = summary
    ols_result.table = table
    ols_result.result = result
    ols_result.goodness = goodness
    ols_result.varstr = varstr

    return ols_result
    

def scailing(df,yname=None):
    """
    ë°ì´í„° í”„ë ˆì„ì„ í‘œì¤€í™” í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - yname: ì¢…ì†ë³€ìˆ˜ ì´ë¦„

    Returns
    -------
    - x_train_std_df: í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    - y_train_std_df: í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    """
    x_train = df.drop([yname],axis=1) if yname else df.copy()
    x_train_std = StandardScaler().fit_transform(x_train)
    x_train_std_df = pd.DataFrame(x_train_std,columns=x_train.columns)
    if yname:
        y_train=df.filter([yname])
        y_train_std = StandardScaler().fit_transform(y_train)
        y_train_std_df = pd.DataFrame(y_train_std,columns=y_train.columns)
    if yname :
        result = (x_train_std,y_train_std)
    else :
        result = x_train_std_df
    return result

def get_best_feature(x_train_std_df):
    pca_model=pca()
    fit = pca_model.fit_transform(x_train_std_df)
    topfeat_df = fit['topfeat']
    best = topfeat_df.query("type=='best'")
    feature = list(set(list(best['feature'])))
    return (feature,topfeat_df)
class LogitResult:
    def __init__(self):
        self._model=None
        self._fit=None
        self._summary=None
        self._prs=None
        self._cmdf=None
        self._result_df=None
        self._odds_ratee_df=None

    @property
    def model(self):
        return self._model
    @model.setter
    def model(self,value):
        self._model = value
    @property
    def fit(self) :
        return self._fit
    @fit.setter
    def fit(self,value):
        self._fit = value

    @property
    def summary(self):
        return self._summary

    @summary.setter
    def summary(self, value):
        self._summary = value

    @property
    def prs(self):
        return self._prs

    @prs.setter
    def prs(self, value):
        self._prs = value

    @property
    def cmdf(self):
        return self._cmdf

    @cmdf.setter
    def cmdf(self, value):
        self._cmdf = value

    @property
    def result_df(self):
        return self._result_df

    @result_df.setter
    def result_df(self, value):
        self._result_df = value

    @property
    def odds_rate_df(self):
        return self._odds_rate_df

    @odds_rate_df.setter
    def odds_rate_df(self, value):
        self._odds_rate_df = value    
def my_logit(data,y,x):
    """
    ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """

    # ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    df = data.copy()

    # ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if type(x) !=list:
        x= [x]
    # ì¢…ì†ë³€ìˆ˜~ë…ë¦½ë³€ìˆ˜1+ë…ë¦½ë³€ìˆ˜2+ë…ë¦½ë³€ìˆ˜3+... í˜•íƒœì˜ ì‹ì„ ìƒì„±
    expr = "%s~%s" %(y,"+".join(x))
    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = logit(expr,data=df)

    fit= model.fit()
    # ë¶„ì„ê²°ê³¼ì˜ ì €ì¥
    summary = fit.summary   
    # ì˜ì‚¬ê²°ì • ê³„ìˆ˜
    prs = fit.prsquared

    ## ì˜ˆì¸¡ê²°ê³¼ë¥¼ ë°ì´í„° í”„ë ˆì„ì— ì¶”ê°€
    df['ì˜ˆì¸¡ê°’'] = fit.predict(df.drop([y],axis=1))
    df['ì˜ˆì¸¡ê²°ê³¼'] = df['ì˜ˆì¸¡ê°’']>0.5

    ## í˜¼ë™í–‰ë ¥ 
    cm = confusion_matrix(df[y],df['ì˜ˆì¸¡ê²°ê³¼'])
    tn,tp,   fn,fp = cm.ravel()
    cmdf = pd.DataFrame(cm,index =['True', 'False'], columns=['Positive', 'Negative'])
    ## RAS
    ras = roc_auc_score(df[y],df['ì˜ˆì¸¡ê²°ê³¼'])
    # ìœ„ì–‘ì„±ìœ¨, ì¬í˜„ìœ¨, ì„ê³„ê°’(ì‚¬ìš©ì•ˆí•¨)
    fpr, tpr, thresholds = roc_curve(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ì •í™•ë„
    acc = accuracy_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ì •ë°€ë„
    pre = precision_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])
    ## ì¬í˜„ìœ¨
    recall = recall_score(df[y],df['ì˜ˆì¸¡ê²°ê³¼'])
    # F1 score
    f1 = f1_score(df[y],df['ì˜ˆì¸¡ê²°ê³¼'])
    # ìœ„ì–‘ì„±ìœ¨
    fallout = fp / (fp + tn)

    # íŠ¹ì´ì„±
    spe = 1 - fallout

    result_df = pd.DataFrame({'ì„¤ëª…ë ¥(Pseudo-Rsqe)': [fit.prsquared], 'ì •í™•ë„(Accuracy)':[acc], 'ì •ë°€ë„(Precision)':[pre], 'ì¬í˜„ìœ¨(Recall, TPR)':[recall], 'ìœ„ì–‘ì„±ìœ¨(Fallout, FPR)': [fallout], 'íŠ¹ì´ì„±(Specificity, TNR)':[spe], 'RAS': [ras], 'f1_score':[f1]})
    # ì˜¤ì¦ˆë¹„
    coef = fit.params
    odds_rate = np.exp(coef)
    odds_rate_df = pd.DataFrame(odds_rate, columns=['odds_rate'])
    
    #return (model, fit, summary, prs, cmdf, result_df, odds_rate_df)
    logit_result = LogitResult()
    logit_result.model = model
    logit_result.fit = fit
    logit_result.summary = summary
    logit_result.prs = prs
    logit_result.cmdf = cmdf
    logit_result.result_df = result_df
    logit_result.odds_rate_df = odds_rate_df

    return logit_result


def exp_timedata(data,yname,sd_model="m",max_diff=1):
    df = data.copy()

    ## ë°ì´í„° ì •ìƒì„± ì—¬ë¶€
    stationality = False

    ## ë°˜ë³µ ìˆ˜í–‰ íšŸìˆ˜

    count = 0 

    # ê²°ì¸¡ì¹˜ ì¡´ì¬ ì—¬ë¶€
    na_count = df[yname].isnull().sum()
    print('ê²°ì¸¡ì¹˜ ìˆ˜ : ',na_count)

    ## Box Plot
    sb.boxplot(data=df, y=yname)
    plt.show()
    plt.close()

    ## ì‹œê³„ì—´ ë¶„í•´

    model_name ='multiplicative' if sd_model=='m' else 'additive'
    sd = seasonal_decompose(df[yname],model=model_name)

    figure = sd.plot()
    figure.set_figwidth(15)
    figure.set_figheight(16)
    fig, ax1,ax2,ax3,ax4 = figure.get_children()
    figure.subplots_adjust(hspace = 0.4)
    ax1.set_ylabel("Original")
    ax1.grid(True)
    ax2.grid(True)
    ax3.grid(True)
    ax4.grid(True)

    plt.show()

    while not stationality:
        if count == 0 :
            print("=========== ì›ë³¸ ë°ì´í„° ===========")
        else : 
            print("=========== %dì°¨ ì°¨ë¶„ ë°ì´í„° ===========" % count)
        
        # ADF test 
        ar = adfuller(df[yname])
        ## ë¦¬ìŠ¤íŠ¸ë¥¼ ì›ì†Œë¡œ ê°–ëŠ” ë”•ì…”ë„ˆë¦¬
        ardict = {
            'ê²€ì •í†µê³„ëŸ‰ (ADF Statistic) ' : [ar[0]],
            'p-value ':[ar[1]],
            'ìµœì  ì°¨ìˆ˜ ':[ar[2]],
            'ê´€ì¸¡ì¹˜ ê°œìˆ˜':[ar[3]]
        }
        for key,value in ar[4].items() : 
            ardict['ê¸°ê°ê°’ %s' % key] = value
        
        stationality = ar[1]<0.05
        ardict['ë°ì´í„° ì •ìƒì„± ì—¬ë¶€(0=Flase,1=True)'] = stationality

        ardf = pd.DataFrame(ardict,index = ['ADF']).T
        print(tabulate(ardf, headers=["ADF", ""], tablefmt='psql', numalign="right"))
    
        # ACF, PACF ê²€ì •
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))
        fig.subplots_adjust(hspace=0.4)

        ax1.title.set_text("Original")
        sb.lineplot(data=df, x=df.index, y=yname, ax=ax1)

        ax2.title.set_text("ACF Test")
        plot_acf(df[yname], ax=ax2)
        
        ax3.title.set_text("PACF Test")
        plot_pacf(df[yname], ax=ax3)
        
        plt.show()
        plt.close()

        # ì°¨ë¶„ ìˆ˜í–‰
        
        df = df.diff().dropna()

        ## ë°˜ë³µì„ ê³„ì†í• ì§€ ì—¬ë¶€ íŒë‹¨
        count +=1
        if count == max_diff:
            break

def set_datetime_index(df,field = None, inplace = False):
    """
        ë°ì´í„° í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Parameters
        -------
        - df: ë°ì´í„° í”„ë ˆì„
        - inplace: ì›ë³¸ ë°ì´í„° í”„ë ˆì„ì— ì ìš© ì—¬ë¶€

        Returns
        -------
        - ì¸ë±ìŠ¤ê°€ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„° í”„ë ˆì„
    """
    if inplace:
        if field is not None :
            df.set_index(field,inplace = True)
        df.index = pd.DatetimeIndex(df.index.values,freq = df.index.inferred_freq)
        df.sort_index(inplace = True)
    else : 
        cdf = df.copy()
        if field is not None :
            cdf.set_index(field,inplace = True)

        cdf.index = pd.DatetimeIndex(cdf.index.values,freq = cdf.index.inferred_freq)
        cdf.sort_index(inplace=True)
        return cdf


def convertPoly(data,degree=2,include_bias=False):
    poly = PolynomialFeatures(degree=degree,include_bias=include_bias)
    fit = poly.fit_transform(data)
    x= pd.DataFrame(fit,columns=poly.get_feature_names_out())
    return x 

def getTrend(x,y,degree=2,value_count = 100):
    coeff = np.polyfit(x,y,degree)
    if type(x) == 'list' :
        minx = min(x)
        maxx= max(x)
    else : 
        minx = x.min()
        maxx = x.max()

    
    vtrend = np.linspace(minx,maxx,value_count)
    ttrend = coeff[-1]
    for i in range(0,degree):
        ttrend += coeff[i] * vtrend**(degree - i)
    return vtrend,ttrend


def regplot(x_left, y_left, y_left_pred=None, left_title=None, x_right=None, y_right=None, y_right_pred=None, right_title=None, figsize=(10, 5), save_path=None):
    subcount = 1 if x_right is None else 2
    
    fig, ax = plt.subplots(1, subcount, figsize=figsize)
    
    axmain = ax if subcount == 1 else ax[0]
    
    # ì™¼ìª½ ì‚°ì ë„
    sb.scatterplot(x=x_left, y=y_left, label='data', ax=axmain)
    
    # ì™¼ìª½ ì¶”ì„¸ì„ 
    x, y = getTrend(x_left, y_left)
    sb.lineplot(x=x, y=y, color='blue', linestyle="--", ax=axmain)
    
    # ì™¼ìª½ ì¶”ì •ì¹˜
    if y_left_pred is not None:
        sb.scatterplot(x=x_left, y=y_left_pred, label='predict', ax=axmain)
        # ì¶”ì •ì¹˜ì— ëŒ€í•œ ì¶”ì„¸ì„ 
        x, y = getTrend(x_left, y_left_pred)
        sb.lineplot(x=x, y=y, color='red', linestyle="--", ax=axmain)
    
    if left_title is not None:
        axmain.set_title(left_title)
        
    axmain.legend()
    axmain.grid()
    
    
    if x_right is not None:
        # ì˜¤ë¥¸ìª½ ì‚°ì ë„
        sb.scatterplot(x=x_right, y=y_right, label='data', ax=ax[1])
        
        # ì˜¤ë¥¸ìª½ ì¶”ì„¸ì„ 
        x, y = getTrend(x_right, y_right)
        sb.lineplot(x=x, y=y, color='blue', linestyle="--", ax=ax[1])
    
        # ì˜¤ë¥¸ìª½ ì¶”ì •ì¹˜
        if y_right_pred is not None:
            sb.scatterplot(x=x_right, y=y_right_pred, label='predict', ax=ax[1])
            # ì¶”ì •ì¹˜ì— ëŒ€í•œ ì¶”ì„¸ì„ 
            x, y = getTrend(x_right, y_right_pred)
            sb.lineplot(x=x, y=y, color='red', linestyle="--", ax=ax[1])
        
        if right_title is not None:
            ax[1].set_title(right_title)
            
        ax[1].legend()
        ax[1].grid()
    
    if save_path is not None:
        plt.savefig(save_path, dpi=300)
        
    plt.show()
    plt.close()

def ml_ols(data,xnames,yname,degree=1,test_size=0.25,scailing=False,random_state=777):
    ## í‘œì¤€í™” ì•ˆë˜ìˆìœ¼ë©´ í‘œì¤€í™” ìˆ˜í–‰
    if scailing:
        data =scailing(data)

     # ë…ë¦½ë³€ìˆ˜ ì´ë¦„ì´ ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ì—ˆë‹¤ë©´ ì½¤ë§ˆ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if type(xnames) == str:
        xnames = xnames.split(',')
    # ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ
    x = data.filter(xnames)
    
    # ì¢…ì†ë³€ìˆ˜ ì¶”ì¶œ
    y = data[yname]
    # 2ì°¨ì‹ ì´ìƒìœ¼ë¡œ ì„¤ì •ë˜ì—ˆë‹¤ë©´ ì°¨ìˆ˜ì— ë§ê²Œ ë³€í™˜
    if degree > 1:
        x = convertPoly(x, degree=degree)
    
    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨ì´ 0ë³´ë‹¤ í¬ë‹¤ë©´ ë¶„í•  ìˆ˜í–‰
    if test_size > 0:
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)
    else:
        x_train = x
        y_train = y
        x_test = None
        y_test = None
    # íšŒê·€ë¶„ì„ ìˆ˜í–‰
    model = LinearRegression()
    fit = model.fit(x_train, y_train)
    
    result = OlsResult()
    result.model = model
    result.fit = fit
    result.coef = fit.coef_
    result.intercept = fit.intercept_

    result.x_train = x_train.copy()
    result.y_train = y_train.copy()
    result.train_pred = result.fit.predict(result.x_train)
    
    if x_test is not None and y_test is not None:
        result.x_test = x_test.copy()
        result.y_test = y_test.copy()
        result.test_pred = result.fit.predict(result.x_test)
        result.setRegMetric(y_train, result.train_pred, y_test, result.test_pred)
        
    else:
        result.setRegMetric(y_train, result.train_pred)
        
    # ì ˆí¸ê³¼ ê³„ìˆ˜ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ê²°í•©
    params = np.append(result.intercept, result.coef)    
    
    # ìƒìˆ˜í•­ ì¶”ê°€í•˜ê¸°
    designX = x.copy()
    designX.insert(0, 'ìƒìˆ˜', 1)   
    
    # í–‰ë ¬ê³± êµ¬í•˜ê¸°
    dot = np.dot(designX.T,designX)
    
    # í–‰ë ¬ê³±ì— ëŒ€í•œ ì—­í–‰ë ¬ 
    inv = np.linalg.inv(dot)  
    
    # ì—­í–‰ë ¬ì˜ ëŒ€ê°ì„  ë°˜í™˜  
    dia = inv.diagonal()
    
    # í‰ê·  ì œê³±ì˜¤ì°¨ êµ¬í•˜ê¸°
    predictions = result.fit.predict(x)
    MSE = (sum((y.values-predictions)**2)) / (len(designX)-len(designX.iloc[0]))
    
    # í‘œì¤€ì˜¤ì°¨
    se_b = np.sqrt(MSE * dia)
    
    # tê°’
    ts_b = params / se_b
    
    # pê°’
    p_values = [2*(1-stats.t.cdf(np.abs(i),(len(designX)-len(designX.iloc[0])))) for i in ts_b]
    
    # vif
    vif = []
    # ë£¬í˜„ë°ì´í„°ì— ëŒ€í•œ ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ë¥¼ ê²°í•©í•œ ì™„ì „í•œ ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„
    data= x_train.copy()
    data[yname] = y_train

    for i, v in enumerate(x_train.column):
        j = list(data.columns).index(v)
        vif.append(variance_inflation_factor(data, j))
    
    # ê²°ê³¼í‘œ êµ¬ì„±í•˜ê¸°
    result.table = pd.DataFrame({
        "ì¢…ì†ë³€ìˆ˜": [yname] * len(x_train.columns),
        "ë…ë¦½ë³€ìˆ˜": x_train.columns,
        "B": result.coef[0],
        "í‘œì¤€ì˜¤ì°¨": se_b[1:],
        "Î²": 0,
        "t": ts_b[1:],
        "ìœ ì˜í™•ë¥ ": p_values[1:],
        "VIF": vif,
    })   
    return result
    